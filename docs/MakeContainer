DONE - Help clicker for describing substitions
    * how they work, waht gets substituted.
DONE    - Do some testing on error cases: document what we've already tested.
    * Directory doesn't exist
    * Directory don't have permission
    * File within a directory does not have permission to read (gives you an error message)
    * "notebooks" is not a directory
    * "notebooks/multi" is not a directory

DONE - verify that it works in the container.
    * getTemplates needs to work for container.
    * home directory doesn't seem to register but it's ok since they can use SF template dir.

- fix rerender() issue in other branch and redeploy on dev.
-> retest and also redeploy to CZ.

- continue working on CFG.


Left off on step 5: (let's make a new branch for it on the FE).
usr/global/tools/lorenz/python/optvis-env2/bin/python /usr/gapps/spot/sand/spot.py getTemplates /usr/gapps/spot/datasets/lulesh_gen/100

Steps:
1) Make new branch
2) Get notebook location from command line argument --custom-template="/usr/home/myNewNotebookTemplate"
3) Use location instead of CONFIG['template_notebook']
    * copy and paste the existing template and make some modification to it for testing.
4) Make sure it works for both single and multi templates.
5) Make a new ajax call that will search for the three locations and return a list of notebooks it finds.
6) On the front end, when person clicks on jupyter return ajax call, with notebook list
    and render a modal that contains a select drop down.
7) On selection, open the jupyter notebook selected.
7.5) same thing for multi jupyter.
8) Test it on container mode.

/usr/global/tools/lorenz/python/optvis-env2/bin/python /usr/gapps/spot/sand/spot.py jupyter /usr/gapps/spot/datasets/lulesh_gen/100/2.cali --custom_template=/g/g0/pascal/TNH.ipynb
/usr/global/tools/lorenz/python/optvis-env2/bin/python /usr/gapps/spot/sand/spot.py multi_jupyter /usr/gapps/spot/datasets/lulesh_gen/100 '["49.cali","41.cali","7.cali"]' --custom_template=/g/g0/pascal/zdeb/Tmu.ipynb



Next -
When you click on a jupyter button or multi jupyter button do a popup modal.
in that modal, have a select drop down for all the available templates
    * USE case 1: we want olga and stephanie to easily be able to add templates
    * Use case 2: we want some other scientist to be able to add templates
        * but these templates are only intended for him and his team, no one else
    * at some point we can check in 3 different locations to look in a person's home directory.
-> want to be able to add new templates without editing source files.
    * backend components goes and looks in the 3 locations (static)
       * for example: user's home directory (~/notebooks)
       * /usr/gapps/spot/templates (everybody already has read permissions) - stephanie could drop one in there for everyone
       * one will be the "notebook" directory beneath the (SF) input directory.
        * the name could come from the filename or within the file, the first line.
        *



- Deploy to CZ Dev.

https://business.llnl.gov/records-information-management/#startreview


DONE - BUG - Be able to save new charts and chart tile edits.
    * when adding a new chart, need to add it to the URL parameters.
    * test case where you're starting fresh and are given a URL with checkboxes in it.
DONE - RangeError -> there was a undefined value in count_unique_values_in_chart_
    * this fix allows us to load the spot2 dashboard on marty's new data.
DONE - async issue -> intermittent loading issue with walltime code.

DEPLOY - RZ/CZ and regression test heavily.
CFG -> implement integration for file loading.

navigator.webkitTemporaryStorage.queryUsageAndQuota (
    function(usedBytes, grantedBytes) {
        console.log('we are using ', usedBytes, ' of ', grantedBytes, 'bytes');
    },
    function(e) { console.log('Error', e);  }
);



BUG - https://rzlc.llnl.gov/spot/dcvis/sankey/index.html?runSetId=/usr/workspace/spotdev/martymcf/ale3d/spot_data/&runId=spot1.3month/sedov_a3d8.8d.8p-1&title=sedov_a3d8.8d.8p
    * it can't find the data in localforage, is the key incorrect?
    * or is the data not there?  was it never put there in the first place?
https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?ch_launchdate=1&ch_user=1&sf=/usr/workspace/spotdev/martymcf/ale3d/spot_data/spot1.3month
                props:{
                    filename: runId,
                    data: fileData.Data ,
                    meta: fileData.Globals
                },
    fileData.Data is empty.

/usr/workspace/spotdev/martymcf/ale3d/spot_data/

it happens even with just 1 file:
https://rzlc.llnl.gov/spot/dcvis/?ch_launchdate=1&ch_user=1&sf=/g/g0/pascal/zdeb/twoDbug
Callspot.js 346:
RangeError: Maximum call stack size exceeded
    at https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:2970:17
    at quicksort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:3007:9)
    at sort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:2845:21)
    at quicksort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:3116:12)
    at sort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:2845:21)
    at quicksort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:3116:12)
    at sort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:2845:21)
    at quicksort (https://rzlc.llnl.gov/spot/dcvis/web/js/crossfilter.js:3116:1
It even happens when the data is almost entirely empty with nothing but
one string "cluster" in the object!

Let's try updating the crossfilter library!!  get the latest version
    * will need to retest heavily.

problem is between
6763 and 6766

Firefox seems unaffected -> 10K is fine there.
                    /*$.Deferred(function( deferred ){
                        $( deferred.resolve );
                    })*/


Redeploy to CZ and Regression test thoroughly.


CFG - integration work.  try to do more for the integration work.

Data should load from here:
https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?ch_launchdate=1&ch_user=1&sf=/usr/workspace/spotdev/martymcf/ale3d/spot_data/spot1.3month

spot1.3month -> 5051

“Maximum call stack size exceeded” crossfilter
https://stackoverflow.com/questions/35119862/maximum-call-stack-size-exceeded-crossfilter#35137485

                for( var z=0; z < ST.newp.length; z++ ) {
                    ST.newp[z] = {
                        cluster: ST.newp[z].cluster,
                        "test8": "yes"
                    };
                }


Run this from the command line:
need to figure out why "Data" is not being populated.
/usr/gapps/spot/sand/spot.py getData /usr/workspace/spotdev/martymcf/ale3d/spot_data/spot1.3month '{}' --writeToFile=1 | more
/usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/ale3d_regr/am-gen '{}' --writeToFile=1 | more

After that's fixed, redeploy and notify matt and marty.
Then continue on CFG.

/usr/gapps/spot/sand/spot.py getData /usr/gapps/spot/datasets/lulesh_gen/100 '{}' --writeToFile=1
/usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/combine '{}' --writeToFile=1
/usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/combine4 '{}' --writeToFile=1
/usr/gapps/spot/sand/spot.py getData /usr/gapps/spot/datasets/demos/mpi '{}' --writeToFile=1
/usr/gapps/spot/sand/spot.py getData /usr/workspace/spotdev/martymcf/ale3d/spot_data/spot2/  '{}' --writeToFile=1



    * the issue is "Data" is not in the object sotred i the localforage.  let's check what goes into the localforage.
https://rzlc.llnl.gov/spot/dcvis/sankey/index.html?runSetId=/usr/workspace/spotdev/martymcf/ale3d/spot_data/spot1.3month&runId=sedov_a3d8.8d.8p-2&title=sedov_a3d8.8d.8p

    this.data and this.funcPaths is empty.
    localforage.getItem() -> the object is there with it's Global but no "Data"
    able to access var fileData = runSet.Runs[runId];  but "Data" not present.
3) BUG - multi directory levels. doesn't work for top level directory with
    * /usr/workspace/spotdev/martymcf/ale3d/spot_data/spot2

- https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=
/usr/workspace/spotdev/martymcf/ale3d/spot_data/spot2

DONE - Get numpy working for rzgenie and rzslic.


2022 -> try to get spot to a place where it becomes wrapped up.
    * cut in money.
    * maintenance mode.


DOCKER
docker build -t spot2 --build-arg DEFAULT_SPOTPW=see .

~/install/spot2_container/spotfe/compare-src: npm run watch-walltime

# do this if you need to change any source code files.  if source files change need to rm and rebuild and rerun.
docker rm spot2_debug6

cd ~/install/spot2_container/
docker build -t spot2 .
docker run -v /Users/aschwanden1/datasets/:/data -p 8080:8080/tcp -p 8888:8888/tcp --name spot2_A0 spot2

http://localhost:8080/?sf=lul_sept_28_timeseries

docker exec -it spot2_9 /bin/bash

- run this from the command line in order to test the backend getData call:
docker exec -it spot2_da5 /bin/bash
/opt/conda/bin/python3 /usr/gapps/spot/backend.py --config  /usr/gapps/spot/backend_config.yaml getData /data/lul_sept_28_timeseries '{}'



- permissions for Venv: umask 0002
- Don't use personal venv, use default at the top of spot.py
    * to reproduce the error.
- import numpy
- also put imports at the top.

python3 -c "import numpy; print(numpy.__version__)"

TEST - multi directory, multi level.

- spot1 Data - it might be years before people stop caring about that.
- spot1 infrastructure we will kill in a few months

DONE - need to rerender the walltime page, so that dictionary will be rendered.
DONE - Regression Test for combos/ and combos2/
DONE - catch file not found error.  case where user enters wrong directory OR no permission.
DONE * make walltime work with our dictionary translation for cali files.
    * make an ajax call to get the dictionary
    * ST.RunDictionaryTranslator.set( newData.dictionary );
    * Sample getDictinoary works: /usr/gapps/spot/sand/spot.py getDictionary /usr/gapps/spot/datasets/lulesh_gen/100
DONE - the multiJupyter should only use the files which are cali, skip the other ones
DONE * need to fix jupyter button on per row basis.
    * jupyter button needs to show up for cali files but not JSON files

DONE - fixed a json_runs reporting error (count lines), I thought was marty's issue but wasnt
    * in response to marty's error.
DONE - if there's an error message then pass it up to FE - this way we can diagnose marty's error
    * Default: if nothing selected show the checkboxes
    * CAllspot.js: set_up_params_()
    * right now bug, if you: https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/usr/gapps/spot/datasets/lulesh_gen/100
        * it will try to select the wrong thing.


Fall 2022 Spot2 GUI will end, maintenance after that.
After that I will go back to lorenz.
Caliper will keep going.


DONE - refactor "ch_"+ into a function.



Last week:
1) DONE - implement cache invalidation for that one file:
        * still need to save cache Date
        * get cache Date
        * retrieve mtime.
        * compare cache date to mtime to see if we should bust the cache.
    /usr/gapps/spot/sand/spot.py getCacheFileDate /g/g0/pascal/zdeb/a0/
TEST - make sure that container still works.
Done - deploy to dev and let marty/legendre try it out.
2) DONE - cali & JSON file mixed support.
    * Need to fix layout_used so that checkboxes for both types show up.  after sq.reset(), the layout was corrected because now based on new data.
Do: don't use sq.layout cache unless there's none coming from the BE.
    * Always use fresh values if available.

3) DONE Checkbox what is checked - encode that in the URL, so that checkboxes get checked.

Next:
    * https://rzlc.llnl.gov/spot/dcvis/?sf=/usr/WS1/ale3d/perf_tracking/perf/SIERRA_CLANG/blueos_sierra_clang/develop/performance_profiles.spot2&ch_problem%20name=1&ch_walltime=1&ch_jobsize=1
    * Goto old defaults (later on change those).
    * Is walltime supposed to work for ale3D data?  Walltime should work for ale3d.
        * [Lorenz::REST::Command::runApprovedCommand] Failed to run command: '/usr/global/tools/lorenz/python/optvis-env2/bin/python /usr/gapps/spot/dev/spot.py memory /g/g0/pascal/zdeb/ale3d_regr/pipe/pipe-gen.4d.4p-1' on rzgenie: cali-query: Error: Could not read file /g/g0/pascal/zdeb/ale3d_regr/pipe/pipe-gen.4d.4p-1"
    * support for running our script in their build system.
    * /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/ale3d_regr/xno '{}' --writeToFile=1




DONE - initial implementation: lazy load dictionary lookups.
    * just load without dictionaryTranslation.  then only do dictionary lookups for things that are being displayed.

Was able to get it down to 2 minutes
- the larger run of everything: still takes 2m to run.
- 12 TTFB, 10 - 50 sec to send to FE.
- 46 Seconds on the front end due to double for loop of Runs, followed by data within those runs
- needs to make 13 million loops.
- smaller runs that can fit in the localSTorage cache limit: 5MB or 25MB are very fast now: just 5 to 6 sec.
    * this is because we no longer have to make an ajax request anymore


Next do after Ale3d:
    * pop up or list of other run based buttons (like walltime)


IndexedDB on FE:
- implement indexedDB: DBStorage.js in order to replace:
    sq.saveSummary and sq.getSummary()
- by bypassing the AJAX call, was able to get to get it down to 1 min.
* still need to implement cache invalidation:
    * make an ajax call to figure out the last time that file was updated.

Next:
- let's try caching newData: can not because localStorage has a limit of 25MB total, 5 MB per key.
    * this is by design and can not be changed.
- investigate caching the entire ajax load, instead of making an ajax load on every page load.
    * just use "cachedData"
- investigate caching the: peeledMetricData and the runsData.
- should we implement indexedDB?

Advantages of indexedDB:
1) should be nearly unlimited storage amount
2) can store objects, rather than limit to strings, so should not need to serialize.
3) asynchronous, so won't lock up the browser.



BUG: [Vue warn]: Error in render: "TypeError: Cannot read property '85' of undefined"
    * Can not hover over the X position on compare view.
    * only the middle two points are clickable (is this because our screen isn't wide enough?)
    * https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/g/g0/pascal/zdeb/ale3d_regr/pipe&cache=0&groupby=title&aggregate=sum&launchdate=1582131012.2211015,1593337317.7673728

Lazy load:
    * groupedAndAggregated()
    * it's a computed field.  first truncate this.runs to 200 entries.  this will allow for the rest of the page to load.
    * then do setInterval, 1 second later run this.runs, add 1000 entries per second.
    * Next: Need to get runs() to be recalculated or AggregatedGrouped() func, in setInterval.

Feature: Add support for JSON + Cali
    - don't disable the whole set, just do each run individually.

DONE - Hatchet deploy stuff
DONE - Disable Jupyter button for spot1 - if it's spot1 -> ale3D that should not get jupyter button.
spot2 -> cali files -> jupyter button
DONE - write to file caching
DONE - able to read file for caching and return it.
DONE - 1. Hook up BE to FE
DONE - Translate dictionary so we're not showing "ab" anymore, show the actual strings

2:38s
TTFB        13s
Download    60s
Process run data    46s (2 sections, where double for loop yields 13661648)
Other stuff 15s - 30s.

/usr/gapps/spot/datasets/newdemo/user
- Ale 3d performance:
    * start working on a converter that would write something to disk.
    /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/ale3d_regr/xno '{}' --writeToFile=1
    https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?cache=0&sf=/g/g0/pascal/zdeb/a0

Good News:
    - File size reduced from 700 mb to 120mb
    - 12s TTFB, can be improved with a JSONP include to less than 1 sec.
    - Was able to load the entire data set onto the FE, in just a couple of minutes
        (now the DictionaryTRanslator is taking forever)

Bad News:
    - FE is sluggish with all that data in there.
    - FE loading time takes forever due to DictionaryTranslator



Still to do:
    * start a process to do the JSON file write. (otherwise it will need to do a new fetch).
    * use include request instead of starting a process?




DONE - Blue Bar with the 1 in it.
DONE - Fixed the "jobsize" issue. ~ unsigned int, so it wasn't in dropdown.
DONE - added cache busting parameter.  cache="0"
DONE - Do the yAxis dropdown and try to use the alias.
    * did the backend to pass back alias info to FE, and the FE part and connected them together.
    * I recommend we get more test data for this!
DONE - BUG: unsigned int (numhosts, jobsize) should not come up as a pieChart.

Performance Ale3D stuff:
Update Dev with Marty's code:

1) was able to use the Pools to make a function call.
1.5) Creted a smaller dataset to work with, for easier debugging, since i'm reworking  a lot of stuff on Be.
2) wrote an algorithm to break up the workload into X arrays to be sent to each pool process
3) now, reworking the algorithm which sends the YAxis data because currently it's just sending 1 run, but we want all 50 or all 300 runs.
    * in that process, to get the maximum space savings, i am restructuring how the data gets sent to FE. (only showing function path one time per 300/Y runs)

** made a new paramter called : "poolCount"

Ale3d:
DONE * need to make it JSON again, and compare size difference with not JSON.  this way FE won't have to turn it into JSON.  let's make it look like what the FE was using before.
* make sure runs_subsets is being split up correctly
    - let's create smaller data files that will make it easier to debug.
* Line 153 -> still need to combine the pools and return total, not just pool_res[1]
    - do this after we fix the performance problems.
* create a test to make sure it's correct. pool timing don't make sense.

- parallelize multiple files using the technique in spot.py
    * table string is currently at the end, after all subprocessing has completed.
    * there needs to be a table string for each subprocess
    * make_table_str needs to be inside the subprocess.
    try:
        cali_json = multiprocessing.Pool(18).map( _cali_to_json, _prependDir(filepath, subpaths))
    except:
    python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/tow2 '{}' | more

- verify size difference.
- Try Marty's Ale3D - entire set and see what the reduction would be.
    * keeping each one separate.
- str replace -> make sure that it replaces the entire contents between the slashes, not just a sub part of it.
- Add JSON wrapper, so it looks just like it looked before.


1. Figure out the ratio of Performance (compare.js) vs Meta Data (crossfilter)
    * let's write a script to actually calculate the difference.
    * ~/zdeb/globals_vs_meta (tow2) / ~/zdeb/globals_vs_meta2 ( all in sub0)
2. Turn it into a table with strings on BE and then print out as a string and not rely on json.dumps.
    watch /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/tow2 '{}'
    /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/tow2 '{}' >> ~/zdeb/compressed
    * the new method takes 12 sec.
    * old: 0.53 sec, before we did

Now with Multi porcessing: (depending on number of pools)
    * 8 xno files takes 12 seconds, 18, 9 sec
    * tow2 takes 3 sec, 4.6 sec 262 dictionary values, 372 data values
    * xn1 takes 11 sec (TTFB), dictionary = 239, data values = 377
    * xn1 with 18 sub, 38 pools, takes 8.8 sec, xn1 48/48  takes 16 seconds, 28/28 takes 11 sec
    * a0: 95 seconds (58 splits, 58 pools), 93 sec (18 splits, 18 pools)




Profile it like this:
rm ~/zdeb/perf/xn; python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/xn '{}' >> ~/zdeb/perf/xn
cat ~/zdeb/perf/xn | grep -v 'problem' | grep -v 'generator' | awk '$4 > 0.1'

getAllJsonRuns is only 7 out of 53 seconds.
encoder.py:413(_iterencode)  33 sec


https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/g/g0/pascal/zdeb/xn1
Profiling: from FE: just TTFB
all xno -> 8 files
with S => 3.54 seco, 3.69s, 3.15s
without S => 9.33, 43s, 11s

a0 -> the entire data set of Ale3d.
with S = 23s, 18s, 24s, 18s, 23s
without S => timeout. (60s+).


1. Solve sorting issue - marty
2. Clean up work for the api, data that's returned, communicate with david for this.



- commit the 2 changes:
    * steph's fix to the spot.py
    * the push+script changes.

check spot2_container and update the FE/BE branch to point to the latest.


set a UMASK before we start.
umask 0002
that modifies in the current shell.


When doing deploy: do CZ first.  Test.  Then do RZ.
Need to remove old github, contact Matt if permission issues.
do deploy at 1pm



Clean up: Delete dot files: check github to see the dot files and delete them.
.sasscache
.idea



Clean up the interface between spotBE and spotFE.




DONE - Deploy latest to CZ Dev: clone new repo there.  Smoke Test.
- Do full regression test for deploy.

Issues with Ale3d:
    1) last layer doesn't appear -> non-issue because same thing happens on live for ALL other data sets.
    2) why doesn't it break it apart by title "/g/g0/pascal/zdeb/ale3d_all" -> because there are only 4 different titles: /usr/gapps/spot/sand/spot.py getData ~/zdeb/ale3d_all '{}' | grep 'title'

    3) Pipe Gen - https://rzlc.llnl.gov/spot/dcvis/?sf=/usr/workspace/spotdev/martymcf/ale3d/perf/2021-01-13/performance_profiles/spot2&aggregate=sum&groupby=problem%20name&problem_name=pipe-gen
            * the first pipe gen graph does not show up.
            * perhaps this is because the values are all 0.
- Caching is an issue -> everytime want to start clean, need to create a new dir and copy files.



DONE - 2) Move over changes -> the 2 Ale3D fixes
DONE - Ale3D data set -> Marty Spot1 files: https://rzlc.llnl.gov/spot/dcvis/?sf=/usr/workspace/spotdev/martymcf/ale3d/spot1-files
- why is it graphing 55 for all the values?  instead of all the different values
    * subset datasets https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?xaxis=launchdate&sf=/g/g0/pascal/tes4&groupby=dataSetKey&aggregate=sum
    * https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/g/g0/pascal/tes6
    * https://rzlc.llnl.gov/spot/#/charts/%2Fusr%2Fworkspace%2Fspotdev%2Fmartymcf%2Fale3d%2Fspot1-files
    * at the 4th layers something is still not right:
    "generator/build ghost elem/exchange and finalize/breakdown ghost elements": {
                    "yAxis": 0.0
                },
    *

DONE - Redeploy RZ Dev with new BE clone ->
DONE - Create subsets of the Ale3D dataset, with just 4 files in it.
DONE - sort the checkboxes at the top of the page of the spot2 dashboard.
    * although sorting is done, need to regression test and see if it didn't break anything
    * because it was commented out, means that it was probably breaking something.
DONE - EtcBucket limit to 200.



https://rzlc.llnl.gov/spot/dcvis/?sf=/usr/workspace/spotdev/martymcf/ale3d/spot1-files&groupby=title&aggregate=sum
/usr/gapps/spot/dev/spot.py getData /usr/gapps/spot/datasets/test_marty '{}' | more
    * resolve 0 issues.
/Users/aschwanden1/spot_my_changes.py

- recheck everything out into new clone and then integrate spot_my_changes
    * make sure we don't overwite existing changes.

DONE - Container -> got walltime working
DONE - Container -> got timeseries working -> had to implement ajax call in a way that worked for the container.
DONE - fixed Environment issues - fix the environemnt.js
DONE - /demos/mem - this does not work for some reason, need to find out why
DONE - Container: MultiJupyter on container -> if URL string too long from too many selections, causes hanging without error message
    * Lowered the limit on the number of characters, which should mitigate the issue.
    * but not sure where the character limit in the docker server is coming from.


- Need to reclone the whole repo and copy changes to it.



- fix walltime for container that jsonP call need ot use the URL host

DONE - currently it's trying to use: lc.llnl.gov which is not right, it should use the current host. (dont hard code localhost)

- app.js only add "/data/" if it's not present in that string that's given
    * don't want people to be able to supply ../etc/
    * realpath -> changes it into actual location
    * translate realpath into an absolute location
    * add /data/ if not exists.
- I'll need to test both spotfe/spotbe in both Container and Noncontainer
    * don't worry about which user is testing.
    * Matt will test charliecloud.

- consider moving to prod mode for Vue.
- possibly look into websocket error
    * who knows if its important or not.

Debuging the python command line:
    from pprint import pprint
    pprint(subpaths)

        except:
            error_me = sys.exc_info()
            pprint(error_me)
            print("Next entry.")
            print()



SPOTPW=see  docker run -e SPOTPW -v /Users/aschwanden1/datasets/:/data -p 8080:8080/tcp -p 8888:8888/tcp --name spot2_d32 spot2


The above will start a debugging session where you or on the docker image:
(base) root@bbe7b70e2409:/usr/gapps/spot# ls /data/lul_sept_28_timeseries/
200924-16330964138.cali  200924-16420956733.cali  200924-16475759479.cali
200924-16383266200.cali  200924-16435357269.cali  200924-17012261057.cali
200924-16394856104.cali  200924-16444657823.cali  200924-17025362173.cali
200924-16401756144.cali  200924-16454258362.cali
200924-16410956192.cali  200924-16465458917.cali

Then you can see all the cali files in your /data/lul_sept_28_timeseries dir:

Works:
http://localhost:8080/?sf=lul_sept_28_timeseries

In Input field only need to enter: lul_sept_28_timeseries

Put data in here: /install/spot2_container/spotbe/demos

From Legendre:
I’ve updated Joe’s SPOT container and added instructions in the README.md for how to build and run it.  It mostly works, but I’m hitting a couple issues:



Docker: I’m getting a build error on this command: docker build -t spot2 .
#14 0.470 CMake Error: The source directory "/usr/gapps/spot/Caliper" does not appear to contain CMakeLists.txt.

Once i checked out the submodules this error message went away:
git submodule update --init --recursive




Container:
- https://lc.llnl.gov/bitbucket/projects/SPOT2/repos/spot2_container/browse
- https://github.com/hpc/charliecloud
- https://hpc.github.io/charliecloud/

Left off trying to install charliecloud
* i tried to install:
aschwanden1@doc ~/Downloads/charliecloud-master: ./autogen.sh
but there was a problem with
+ autoreconf --force --install -Wall -Werror
./autogen.sh: line 56: autoreconf: command not found

- need to find out how to install autoreconf and try to reinstall it.
After that install charliecloud.
- then after that follow the directions for the spot2_container: https://lc.llnl.gov/bitbucket/projects/SPOT2/repos/spot2_container/browse





Ok, so I was able to change the URL such that It calls from http://localhost:8080 in the container for the failing jsonP callback.  But, it’s now calling lora.cgi/jsonp.

So, I’m going to use the app.js file to specify a new endpoint that will call backend.py, just like the /getData call in app.js.

There’s a memory call which returns all the info needed for the front end, (the call for noncontainer is:

/usr/gapps/spot/venv_python/bin/python3 /usr/gapps/spot/dev/spot.py memory lul_sept_28_timeseries/200924-16410956192.cali



Parcel not found:
Answer:
This means you need to run:
From here: ~/install/spot2_github/spotfe/compare-src
npm install


Average run time over 500 executions repeated 4 times
--------------------
Library: ujson
Version: 1.33
ujson.dumps(data): 1.97361302376 (total) 0.000986806511879 (per call)
ujson.loads(data): 2.05873394012 (total) 0.00102936697006 (per call)
--------------------
Library: simplejson
Version: 3.3.0
simplejson.dumps(data): 3.24183320999 (total) 0.001620916605 (per call)
simplejson.loads(data): 2.20791387558 (total) 0.00110395693779 (per call)
--------------------
Library: jsonlib2
Version: (1, 3, 10)
jsonlib2.dumps(data): 2.211810112 (total) 0.001105905056 (per call)
jsonlib2.loads(data): 2.55381131172 (total) 0.00127690565586 (per call)
--------------------
Library: json
Version: 2.0.9
json.dumps(data): 2.35674309731 (total) 0.00117837154865 (per call)
json.loads(data): 5.23104810715 (total) 0.00261552405357 (per call)
--------------------
Library: yajl
Version: None
yajl.dumps(data): 2.85826969147 (total) 0.00142913484573 (per call)
yajl.loads(data): 3.03867292404 (total) 0.00151933646202 (per call)
--------------------
Fastest dumps: ujson 1.97361302376 (total)
Fastest loads: ujson 2.05873394012 (total)




tow2: (2 files)
with dumps: 3.49, 3.49, 3.41, 3.03, 3.65
with dump: 4.71, 5.14, 4.53, 5.16, 4.51 ~ avg 4.75


https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/g/g0/pascal/zdeb/ale3d_regr/sedov&groupby=title&aggregate=sum
sedov: (12 files)
with dumps: 6.82, 6.98, 6.63
with dump: 11.35, 10.11
1.8 mb / 46 mb

with all the files:
with dumps: still timing out, 46s, 41s


xn_no_s: 23 files, just tow files:
https://rzlc.llnl.gov/lorenz_base/dev/pascal/spotfe/?sf=/g/g0/pascal/zdeb/xn_no_s&groupby=title&aggregate=sum
with dumps: 25s, 30.7s, 25.4s




watch /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/tow2 '{}'
/usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/tow2 '{}' >> ~/zdeb/compressed


(base) [pascal@rzslic7:zdeb]$ ls -l xn1
total 5388
-rw------- 1 pascal pascal  358087 Feb  9 19:52 xno-gen.1d.1p.json
-rw------- 1 pascal pascal  929036 Feb  9 19:52 xno.1d.1p.json
-rw------- 1 pascal pascal  364486 Feb  9 19:52 xno_large-gen.1d.1p.json
-rw------- 1 pascal pascal  927871 Feb  9 19:52 xno_large.1d.1p.json
-rw------- 1 pascal pascal  456980 Feb  9 19:52 xno_large4-gen.4d.4p.json
-rw------- 1 pascal pascal 1171256 Feb  9 19:52 xno_large4.4d.4p.json
-rw------- 1 pascal pascal  364503 Feb  9 19:52 xno_modequip-gen.1d.1p.json
-rw------- 1 pascal pascal  899964 Feb  9 19:52 xno_modequip.1d.1p.json
(base) [pascal@rzslic7:zdeb]$ ls -l sedov
total 6624
-rw------- 1 pascal pascal 345444 Mar  8 19:31 sedov_a3d-gen.1d.1p.json
-rw------- 1 pascal pascal 509258 Mar  8 19:31 sedov_a3d.1d.1p.json
-rw------- 1 pascal pascal 389402 Mar  8 19:31 sedov_a3d4-gen.4d.4p.json
-rw------- 1 pascal pascal 581240 Mar  8 19:31 sedov_a3d4.4d.4p.json
-rw------- 1 pascal pascal 390361 Mar  8 19:31 sedov_a3d8-gen.8d.8p.json
-rw------- 1 pascal pascal 563829 Mar  8 19:31 sedov_a3d8.8d.8p.json
-rw------- 1 pascal pascal 348486 Mar  8 19:31 sedov_adv-gen.1d.1p.json
-rw------- 1 pascal pascal 824139 Mar  8 19:31 sedov_adv.1d.1p.json
-rw------- 1 pascal pascal 400864 Mar  8 19:31 sedov_adv4-gen.4d.4p.json
-rw------- 1 pascal pascal 989274 Mar  8 19:31 sedov_adv4.4d.4p.json
-rw------- 1 pascal pascal 402364 Mar  8 19:31 sedov_adv8-gen.8d.8p.json
-rw------- 1 pascal pascal 958518 Mar  8 19:31 sedov_adv8.8d.8p.json
(base) [pascal@rzslic7:zdeb]$ du -skh xn1
5.3M	xn1
(base) [pascal@rzslic7:zdeb]$ du -skh sedov
6.5M	sedov
(base) [pascal@rzslic7:zdeb]$ du -ksh a0
43M	a0


XN1 ~ about 8 files
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/xn1 '{}' --poolCount 20 | grep 'function calls'
         551782 function calls (548384 primitive calls) in 9.967 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/xn1 '{}' --poolCount 5 | grep 'function calls'
         550716 function calls (547333 primitive calls) in 10.244 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/xn1 '{}' --poolCount 2 | grep 'function calls'
         550551 function calls (547171 primitive calls) in 18.336 seconds

Sedov about 7 or 8 files or so.
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/sedov '{}' --poolCount 2 | grep 'function calls'
         672036 function calls (668656 primitive calls) in 23.431 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/sedov '{}' --poolCount 20 | grep 'function calls'
         673258 function calls (669860 primitive calls) in 12.564 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/sedov '{}' --poolCount 40 | grep 'function calls'
         675390 function calls (671972 primitive calls) in 17.379 seconds

A0: this is all the files.
python -m cProfile /usr/gapps/spot/dev/spot.py getData /g/g0/pascal/zdeb/a0 '{}' | grep 'function calls'
}         269201604 function calls (146312103 primitive calls) in 65.513 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/a0 '{}' --poolCount 2 | grep 'function calls'
         3648091 function calls (3644711 primitive calls) in 318.389 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/a0 '{}' --poolCount 10 | grep 'function calls'
         3648578 function calls (3645190 primitive calls) in 116.891 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/a0 '{}' --poolCount 20 | grep 'function calls'
         3649325 function calls (3645927 primitive calls) in 95.531 seconds
(base) [pascal@rzslic6:~]$ python -m cProfile /usr/gapps/spot/sand/spot.py getData /g/g0/pascal/zdeb/a0 '{}' --poolCount 40 | grep 'function calls'
         3651453 function calls (3648035 primitive calls) in 135.533 seconds


Size:
(base) [pascal@rzslic9:sand]$ ls -l  ~/zdeb/perf/measure_a0_size
-rw------- 1 pascal pascal 119067849 Mar 12 09:26 /g/g0/pascal/zdeb/perf/measure_a0_size

That's 119 MB.
But, could drop that by:
    * getting rid of spaces
    * compress yAxis string
    * rep 0.0 with 0
Get down to 80 MB.



Update May 2020: Chrome now lets an origin use 60% of the storage device's space (Real nitty gritty: "storage device" is the partition containing the chrome profile directory). Updated article here https://web.dev/storage-for-the-web/#how-much

The rule of thumb is 6% (edit 2015-Jul: was 10%) of the available space on the user's hard drive, less if your origin is using websql, appcache or the filesystem api. The MDN doc mentioning 5mb was outdated and has been updated. The gory details about the current policy are here: https://developer.chrome.com/apps/offline_storage

Note some annoying subtleties:

There is no PERSISTENT storage for indexeddb, only the stuff in the link above about TEMPORARY applies.



Walltime call:
{
    "series": {
        "records": [],
        "globals": {
            "spot.metrics": "#sum.sum#duration#inclusive",
            "figure_of_merit": "7200.000000",
            "elapsed_time": "64.000000",
            "region_balance": "10",
            "region_cost": "4",
            "num_regions": "11",
            "problem_size": "72",
            "iterations": "1920000",
            "threads": "31",
            "jobsize": "5",
            "cluster": "treetops",
            "cmdline": "[-runflag -f",
            "libraries": "GCC-4.93",
            "executablepath": "/hosts/bin/serv",
            "launchdate": "1566467749",
            "user": "boehme3",
            "cali.channel": "spot",
            "cali.caliper.version": "2.2.0-dev"
        },
        "attributes": {
            "adiak.category": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "adiak.category",
                "cali.attribute.prop": "12",
                "cali.attribute.type": "string"
            },
            "adiak.type": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "adiak.type",
                "cali.attribute.prop": "12",
                "cali.attribute.type": "string"
            },
            "avg#inclusive#sum#time.duration": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "avg#inclusive#sum#time.duration",
                "cali.attribute.prop": "65",
                "cali.attribute.type": "double"
            },
            "cali.attribute.name": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "cali.attribute.name",
                "cali.attribute.type": "string"
            },
            "cali.attribute.prop": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "cali.attribute.prop",
                "cali.attribute.type": "int"
            },
            "cali.attribute.type": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "cali.attribute.type",
                "cali.attribute.type": "type"
            },
            "cali.caliper.version": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "cali.caliper.version",
                "cali.attribute.prop": "588",
                "cali.attribute.type": "string"
            },
            "cali.channel": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "cali.channel",
                "cali.attribute.prop": "588",
                "cali.attribute.type": "string"
            },
            "cluster": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "cluster",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "string",
                "cali.attribute.type": "string"
            },
            "cmdline": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "cmdline",
                "cali.attribute.prop": "524",
                "adiak.category": "runinfo",
                "adiak.type": "set of string",
                "cali.attribute.type": "string"
            },
            "elapsed_time": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "elapsed_time",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "double",
                "cali.attribute.type": "double"
            },
            "executablepath": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "executablepath",
                "cali.attribute.prop": "524",
                "adiak.category": "binary",
                "adiak.type": "path",
                "cali.attribute.type": "string"
            },
            "figure_of_merit": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "figure_of_merit",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "double",
                "cali.attribute.type": "double"
            },
            "iterations": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "iterations",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "jobsize": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "jobsize",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "launchdate": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "launchdate",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "date",
                "cali.attribute.type": "uint"
            },
            "libraries": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "libraries",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "set of path",
                "cali.attribute.type": "string"
            },
            "max#inclusive#sum#time.duration": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "max#inclusive#sum#time.duration",
                "cali.attribute.prop": "65",
                "cali.attribute.type": "double"
            },
            "min#inclusive#sum#time.duration": {
                "is_global": false,
                "is_nested": false,
                "cali.attribute.name": "min#inclusive#sum#time.duration",
                "cali.attribute.prop": "65",
                "cali.attribute.type": "double"
            },
            "num_regions": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "num_regions",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "problem_size": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "problem_size",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "region_balance": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "region_balance",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "region_cost": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "region_cost",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "spot.metrics": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "spot.metrics",
                "cali.attribute.prop": "512",
                "cali.attribute.type": "string"
            },
            "threads": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "threads",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "int",
                "cali.attribute.type": "int"
            },
            "user": {
                "is_global": true,
                "is_nested": false,
                "cali.attribute.name": "user",
                "cali.attribute.prop": "524",
                "adiak.category": "none",
                "adiak.type": "string",
                "cali.attribute.type": "string"
            }
        }
    },
    "cali_path": "/usr/gapps/spot/datasets/lulesh_gen/100/33.cali"
}


3.7s    12 mb
8.2s,10,7s    49 mb
26s        196 mb



data is empty here:
cachedData.Runs = Object.assign(cachedData.Runs, runs0);
                cachedData.RunDataMeta = Object.assign(cachedData.RunDataMeta, newData.RunDataMeta);
                cachedData.RunGlobalMeta = Object.assign(cachedData.RunGlobalMeta, newData.RunGlobalMeta);
                cachedData.RunSetMeta = Object.assign(cachedData.RunSetMeta, newData.RunSetMeta);
                cachedData.runCtimes = newData.runCtimes; // delete runs from cache that were deleted on backend

                deletedRuns = newData.deletedRuns || [];
                deletedRuns.forEach(function (deletedRun) {
                  return delete cachedData.Runs[deletedRun];
                });
                window.cachedData = cachedData; // cache newest version of data

                _context3.next = 91;
                return _localforage.default.setItem(dataSetKey, cachedData);
